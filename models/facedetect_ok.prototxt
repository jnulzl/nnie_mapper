layer {
  name: "input0"
  type: "Input"
  top: "input0"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 320
      dim: 320
    }
  }
}
layer {
  name: "259"
  type: "Convolution"
  bottom: "input0"
  top: "259"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 2
    stride: 2
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "260/bn"
  type: "BatchNorm"
  bottom: "259"
  top: "259"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "260/scale"
  type: "Scale"
  bottom: "259"
  top: "259"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "261"
  type: "ReLU"
  bottom: "259"
  top: "259"
}
layer {
  name: "262"
  type: "Convolution"
  bottom: "259"
  top: "262"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 8
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "263/bn"
  type: "BatchNorm"
  bottom: "262"
  top: "262"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "263/scale"
  type: "Scale"
  bottom: "262"
  top: "262"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "264"
  type: "ReLU"
  bottom: "262"
  top: "262"
}
layer {
  name: "265"
  type: "Convolution"
  bottom: "262"
  top: "265"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "266/bn"
  type: "BatchNorm"
  bottom: "265"
  top: "265"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "266/scale"
  type: "Scale"
  bottom: "265"
  top: "265"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "267"
  type: "ReLU"
  bottom: "265"
  top: "265"
}
layer {
  name: "268"
  type: "Convolution"
  bottom: "265"
  top: "268"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 16
    stride: 2
    stride: 2
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "269/bn"
  type: "BatchNorm"
  bottom: "268"
  top: "268"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "269/scale"
  type: "Scale"
  bottom: "268"
  top: "268"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "270"
  type: "ReLU"
  bottom: "268"
  top: "268"
}
layer {
  name: "271"
  type: "Convolution"
  bottom: "268"
  top: "271"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "272/bn"
  type: "BatchNorm"
  bottom: "271"
  top: "271"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "272/scale"
  type: "Scale"
  bottom: "271"
  top: "271"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "273"
  type: "ReLU"
  bottom: "271"
  top: "271"
}
layer {
  name: "274"
  type: "Convolution"
  bottom: "271"
  top: "274"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 16
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "275/bn"
  type: "BatchNorm"
  bottom: "274"
  top: "274"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "275/scale"
  type: "Scale"
  bottom: "274"
  top: "274"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "276"
  type: "ReLU"
  bottom: "274"
  top: "274"
}
layer {
  name: "277"
  type: "Convolution"
  bottom: "274"
  top: "277"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "278/bn"
  type: "BatchNorm"
  bottom: "277"
  top: "277"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "278/scale"
  type: "Scale"
  bottom: "277"
  top: "277"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "279"
  type: "ReLU"
  bottom: "277"
  top: "277"
}
layer {
  name: "280"
  type: "Convolution"
  bottom: "277"
  top: "280"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 16
    stride: 2
    stride: 2
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "281/bn"
  type: "BatchNorm"
  bottom: "280"
  top: "280"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "281/scale"
  type: "Scale"
  bottom: "280"
  top: "280"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "282"
  type: "ReLU"
  bottom: "280"
  top: "280"
}
layer {
  name: "283"
  type: "Convolution"
  bottom: "280"
  top: "283"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "284/bn"
  type: "BatchNorm"
  bottom: "283"
  top: "283"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "284/scale"
  type: "Scale"
  bottom: "283"
  top: "283"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "285"
  type: "ReLU"
  bottom: "283"
  top: "283"
}
layer {
  name: "286"
  type: "Convolution"
  bottom: "283"
  top: "286"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 32
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "287/bn"
  type: "BatchNorm"
  bottom: "286"
  top: "286"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "287/scale"
  type: "Scale"
  bottom: "286"
  top: "286"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "288"
  type: "ReLU"
  bottom: "286"
  top: "286"
}
layer {
  name: "289"
  type: "Convolution"
  bottom: "286"
  top: "289"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "290/bn"
  type: "BatchNorm"
  bottom: "289"
  top: "289"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "290/scale"
  type: "Scale"
  bottom: "289"
  top: "289"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "291"
  type: "ReLU"
  bottom: "289"
  top: "289"
}
layer {
  name: "292"
  type: "Convolution"
  bottom: "289"
  top: "292"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 32
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "293/bn"
  type: "BatchNorm"
  bottom: "292"
  top: "292"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "293/scale"
  type: "Scale"
  bottom: "292"
  top: "292"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "294"
  type: "ReLU"
  bottom: "292"
  top: "292"
}
layer {
  name: "295"
  type: "Convolution"
  bottom: "292"
  top: "295"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "296/bn"
  type: "BatchNorm"
  bottom: "295"
  top: "295"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "296/scale"
  type: "Scale"
  bottom: "295"
  top: "295"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "297"
  type: "ReLU"
  bottom: "295"
  top: "295"
}
layer {
  name: "298"
  type: "Convolution"
  bottom: "295"
  top: "298"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "299/bn"
  type: "BatchNorm"
  bottom: "298"
  top: "298"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "299/scale"
  type: "Scale"
  bottom: "298"
  top: "298"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "300"
  type: "Convolution"
  bottom: "298"
  top: "300"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "301/bn"
  type: "BatchNorm"
  bottom: "300"
  top: "300"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "301/scale"
  type: "Scale"
  bottom: "300"
  top: "300"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "302"
  type: "ReLU"
  bottom: "300"
  top: "300"
}
layer {
  name: "303"
  type: "Convolution"
  bottom: "300"
  top: "303/native"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 2
    pad: 2
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 2
    dilation: 2
  }
}
layer {
  name: "304/bn"
  type: "BatchNorm"
  bottom: "303/native"
  top: "303"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "305"
  type: "Convolution"
  bottom: "295"
  top: "305"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "306/bn"
  type: "BatchNorm"
  bottom: "305"
  top: "305"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "306/scale"
  type: "Scale"
  bottom: "305"
  top: "305"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "307"
  type: "Convolution"
  bottom: "305"
  top: "307"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "308/bn"
  type: "BatchNorm"
  bottom: "307"
  top: "307"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "308/scale"
  type: "Scale"
  bottom: "307"
  top: "307"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "309"
  type: "ReLU"
  bottom: "307"
  top: "307"
}
layer {
  name: "310"
  type: "Convolution"
  bottom: "307"
  top: "310/native"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 3
    pad: 3
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 3
    dilation: 3
  }
}
layer {
  name: "311/bn"
  type: "BatchNorm"
  bottom: "310/native"
  top: "310"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "312"
  type: "Convolution"
  bottom: "295"
  top: "312"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "313/bn"
  type: "BatchNorm"
  bottom: "312"
  top: "312"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "313/scale"
  type: "Scale"
  bottom: "312"
  top: "312"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "314"
  type: "Convolution"
  bottom: "312"
  top: "314"
  convolution_param {
    num_output: 6
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "315/bn"
  type: "BatchNorm"
  bottom: "314"
  top: "314"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "315/scale"
  type: "Scale"
  bottom: "314"
  top: "314"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "316"
  type: "ReLU"
  bottom: "314"
  top: "314"
}
layer {
  name: "317"
  type: "Convolution"
  bottom: "314"
  top: "317"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "318/bn"
  type: "BatchNorm"
  bottom: "317"
  top: "317"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "318/scale"
  type: "Scale"
  bottom: "317"
  top: "317"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "319"
  type: "ReLU"
  bottom: "317"
  top: "317"
}
layer {
  name: "320"
  type: "Convolution"
  bottom: "317"
  top: "320/native"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 5
    pad: 5
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 5
    dilation: 5
  }
}
layer {
  name: "321/bn"
  type: "BatchNorm"
  bottom: "320/native"
  top: "320"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "304/scale"
  type: "Scale"
  bottom: "303"
  top: "303"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "311/scale"
  type: "Scale"
  bottom: "310"
  top: "310"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "321/scale"
  type: "Scale"
  bottom: "320"
  top: "320"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "322"
  type: "Concat"
  bottom: "303"
  bottom: "310"
  bottom: "320"
  top: "322"
  concat_param {
    axis: 1
  }
}
layer {
  name: "323"
  type: "Convolution"
  bottom: "322"
  top: "323"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "324/bn"
  type: "BatchNorm"
  bottom: "323"
  top: "323"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "325"
  type: "Convolution"
  bottom: "295"
  top: "325"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "326/bn"
  type: "BatchNorm"
  bottom: "325"
  top: "325"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "324/scale"
  type: "Scale"
  bottom: "323"
  top: "323"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "326/scale"
  type: "Scale"
  bottom: "325"
  top: "325"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "327"
  type: "Eltwise"
  bottom: "323"
  bottom: "325"
  top: "327"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "328"
  type: "ReLU"
  bottom: "327"
  top: "327"
}
layer {
  name: "373"
  type: "Convolution"
  bottom: "327"
  top: "373"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 64
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "374"
  type: "ReLU"
  bottom: "373"
  top: "373"
}
layer {
  name: "375"
  type: "Convolution"
  bottom: "373"
  top: "375"
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "376"
  type: "Permute"
  bottom: "375"
  top: "376"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "329"
  type: "Convolution"
  bottom: "327"
  top: "329"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 64
    stride: 2
    stride: 2
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "330/bn"
  type: "BatchNorm"
  bottom: "329"
  top: "329"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "330/scale"
  type: "Scale"
  bottom: "329"
  top: "329"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "331"
  type: "ReLU"
  bottom: "329"
  top: "329"
}
layer {
  name: "332"
  type: "Convolution"
  bottom: "329"
  top: "332"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "333/bn"
  type: "BatchNorm"
  bottom: "332"
  top: "332"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "333/scale"
  type: "Scale"
  bottom: "332"
  top: "332"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "334"
  type: "ReLU"
  bottom: "332"
  top: "332"
}
layer {
  name: "335"
  type: "Convolution"
  bottom: "332"
  top: "335"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 128
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "336/bn"
  type: "BatchNorm"
  bottom: "335"
  top: "335"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "336/scale"
  type: "Scale"
  bottom: "335"
  top: "335"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "337"
  type: "ReLU"
  bottom: "335"
  top: "335"
}
layer {
  name: "338"
  type: "Convolution"
  bottom: "335"
  top: "338"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "339/bn"
  type: "BatchNorm"
  bottom: "338"
  top: "338"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "339/scale"
  type: "Scale"
  bottom: "338"
  top: "338"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "340"
  type: "ReLU"
  bottom: "338"
  top: "338"
}
layer {
  name: "341"
  type: "Convolution"
  bottom: "338"
  top: "341"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 128
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "342/bn"
  type: "BatchNorm"
  bottom: "341"
  top: "341"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "342/scale"
  type: "Scale"
  bottom: "341"
  top: "341"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "343"
  type: "ReLU"
  bottom: "341"
  top: "341"
}
layer {
  name: "344"
  type: "Convolution"
  bottom: "341"
  top: "344"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "345/bn"
  type: "BatchNorm"
  bottom: "344"
  top: "344"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "345/scale"
  type: "Scale"
  bottom: "344"
  top: "344"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "346"
  type: "ReLU"
  bottom: "344"
  top: "344"
}
layer {
  name: "385"
  type: "Convolution"
  bottom: "344"
  top: "385"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 128
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "386"
  type: "ReLU"
  bottom: "385"
  top: "385"
}
layer {
  name: "387"
  type: "Convolution"
  bottom: "385"
  top: "387"
  convolution_param {
    num_output: 20
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "388"
  type: "Permute"
  bottom: "387"
  top: "388"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "347"
  type: "Convolution"
  bottom: "344"
  top: "347"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 128
    stride: 2
    stride: 2
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "348/bn"
  type: "BatchNorm"
  bottom: "347"
  top: "347"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "348/scale"
  type: "Scale"
  bottom: "347"
  top: "347"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "349"
  type: "ReLU"
  bottom: "347"
  top: "347"
}
layer {
  name: "350"
  type: "Convolution"
  bottom: "347"
  top: "350"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "351/bn"
  type: "BatchNorm"
  bottom: "350"
  top: "350"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "351/scale"
  type: "Scale"
  bottom: "350"
  top: "350"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "352"
  type: "ReLU"
  bottom: "350"
  top: "350"
}
layer {
  name: "353"
  type: "Convolution"
  bottom: "350"
  top: "353"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 256
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "354/bn"
  type: "BatchNorm"
  bottom: "353"
  top: "353"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "354/scale"
  type: "Scale"
  bottom: "353"
  top: "353"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "355"
  type: "ReLU"
  bottom: "353"
  top: "353"
}
layer {
  name: "356"
  type: "Convolution"
  bottom: "353"
  top: "356"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "357/bn"
  type: "BatchNorm"
  bottom: "356"
  top: "356"
  batch_norm_param {
    use_global_stats: true
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "357/scale"
  type: "Scale"
  bottom: "356"
  top: "356"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "358"
  type: "ReLU"
  bottom: "356"
  top: "356"
}
layer {
  name: "397"
  type: "Convolution"
  bottom: "356"
  top: "397"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 256
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "398"
  type: "ReLU"
  bottom: "397"
  top: "397"
}
layer {
  name: "399"
  type: "Convolution"
  bottom: "397"
  top: "399"
  convolution_param {
    num_output: 20
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "400"
  type: "Permute"
  bottom: "399"
  top: "400"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "359"
  type: "Convolution"
  bottom: "356"
  top: "359"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "360"
  type: "ReLU"
  bottom: "359"
  top: "359"
}
layer {
  name: "361"
  type: "Convolution"
  bottom: "359"
  top: "361"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 64
    stride: 2
    stride: 2
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "362"
  type: "ReLU"
  bottom: "361"
  top: "361"
}
layer {
  name: "363"
  type: "Convolution"
  bottom: "361"
  top: "363"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "364"
  type: "ReLU"
  bottom: "363"
  top: "363"
}
layer {
  name: "405"
  type: "Convolution"
  bottom: "363"
  top: "405"
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "406"
  type: "Permute"
  bottom: "405"
  top: "406"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "498"
  type: "Reshape"
  bottom: "376"
  top: "498"
  reshape_param {
    shape {
      dim: 0
      dim: 4800
      dim: 10
    }
  }
}
layer {
  name: "508"
  type: "Reshape"
  bottom: "388"
  top: "508"
  reshape_param {
    shape {
      dim: 0
      dim: 800
      dim: 10
    }
  }
}
layer {
  name: "518"
  type: "Reshape"
  bottom: "400"
  top: "518"
  reshape_param {
    shape {
      dim: 0
      dim: 200
      dim: 10
    }
  }
}
layer {
  name: "528"
  type: "Reshape"
  bottom: "406"
  top: "528"
  reshape_param {
    shape {
      dim: 0
      dim: 75
      dim: 10
    }
  }
}
layer {
  name: "369"
  type: "Convolution"
  bottom: "327"
  top: "369"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 64
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "370"
  type: "ReLU"
  bottom: "369"
  top: "369"
}
layer {
  name: "371"
  type: "Convolution"
  bottom: "369"
  top: "371"
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "372"
  type: "Permute"
  bottom: "371"
  top: "372"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "381"
  type: "Convolution"
  bottom: "344"
  top: "381"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 128
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "382"
  type: "ReLU"
  bottom: "381"
  top: "381"
}
layer {
  name: "383"
  type: "Convolution"
  bottom: "381"
  top: "383"
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "384"
  type: "Permute"
  bottom: "383"
  top: "384"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "393"
  type: "Convolution"
  bottom: "356"
  top: "393"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 256
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "394"
  type: "ReLU"
  bottom: "393"
  top: "393"
}
layer {
  name: "395"
  type: "Convolution"
  bottom: "393"
  top: "395"
  convolution_param {
    num_output: 4
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "396"
  type: "Permute"
  bottom: "395"
  top: "396"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "403"
  type: "Convolution"
  bottom: "363"
  top: "403"
  convolution_param {
    num_output: 6
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "404"
  type: "Permute"
  bottom: "403"
  top: "404"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "457"
  type: "Reshape"
  bottom: "372"
  top: "457"
  reshape_param {
    shape {
      dim: 0
      dim: 4800
      dim: 2
    }
  }
}
layer {
  name: "467"
  type: "Reshape"
  bottom: "384"
  top: "467"
  reshape_param {
    shape {
      dim: 0
      dim: 800
      dim: 2
    }
  }
}
layer {
  name: "477"
  type: "Reshape"
  bottom: "396"
  top: "477"
  reshape_param {
    shape {
      dim: 0
      dim: 200
      dim: 2
    }
  }
}
layer {
  name: "487"
  type: "Reshape"
  bottom: "404"
  top: "487"
  reshape_param {
    shape {
      dim: 0
      dim: 75
      dim: 2
    }
  }
}
layer {
  name: "488"
  type: "Concat"
  bottom: "457"
  bottom: "467"
  bottom: "477"
  bottom: "487"
  top: "488"
  concat_param {
    axis: 1
  }
}
layer {
  name: "365"
  type: "Convolution"
  bottom: "327"
  top: "365"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 64
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "366"
  type: "ReLU"
  bottom: "365"
  top: "365"
}
layer {
  name: "367"
  type: "Convolution"
  bottom: "365"
  top: "367"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "368"
  type: "Permute"
  bottom: "367"
  top: "368"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "377"
  type: "Convolution"
  bottom: "344"
  top: "377"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 128
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "378"
  type: "ReLU"
  bottom: "377"
  top: "377"
}
layer {
  name: "379"
  type: "Convolution"
  bottom: "377"
  top: "379"
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "380"
  type: "Permute"
  bottom: "379"
  top: "380"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "389"
  type: "Convolution"
  bottom: "356"
  top: "389"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 256
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "390"
  type: "ReLU"
  bottom: "389"
  top: "389"
}
layer {
  name: "391"
  type: "Convolution"
  bottom: "389"
  top: "391"
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    pad: 0
    kernel_size: 1
    kernel_size: 1
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "392"
  type: "Permute"
  bottom: "391"
  top: "392"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "401"
  type: "Convolution"
  bottom: "363"
  top: "401"
  convolution_param {
    num_output: 12
    bias_term: true
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    stride: 1
    dilation: 1
    dilation: 1
  }
}
layer {
  name: "402"
  type: "Permute"
  bottom: "401"
  top: "402"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "416"
  type: "Reshape"
  bottom: "368"
  top: "416"
  reshape_param {
    shape {
      dim: 0
      dim: 4800
      dim: 4
    }
  }
}
layer {
  name: "426"
  type: "Reshape"
  bottom: "380"
  top: "426"
  reshape_param {
    shape {
      dim: 0
      dim: 800
      dim: 4
    }
  }
}
layer {
  name: "436"
  type: "Reshape"
  bottom: "392"
  top: "436"
  reshape_param {
    shape {
      dim: 0
      dim: 200
      dim: 4
    }
  }
}
layer {
  name: "446"
  type: "Reshape"
  bottom: "402"
  top: "446"
  reshape_param {
    shape {
      dim: 0
      dim: 75
      dim: 4
    }
  }
}
layer {
  name: "output0"
  type: "Concat"
  bottom: "416"
  bottom: "426"
  bottom: "436"
  bottom: "446"
  top: "output0"
  concat_param {
    axis: 1
  }
}
layer {
  name: "530"
  type: "Softmax"
  bottom: "488"
  top: "530"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "prediction"
  type: "Concat"
  bottom: "498"
  bottom: "508"
  bottom: "518"
  bottom: "528"
  top: "prediction"
  concat_param {
    axis: 1
  }
}
